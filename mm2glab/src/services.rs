use crate::api::gitlab::{GitLabApi, GitLabClient};
use crate::api::mattermost::{MattermostApi, MattermostClient};
use crate::models::gitlab::Issue;
use crate::models::mattermost::Thread;
use crate::settings::merge_settings_with_args;
use crate::{cli::Args, models::Conversation};

use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use chrono::{Local, TimeZone};
use dialoguer::Editor;
use indicatif::{ProgressBar, ProgressStyle};
use log::debug;
use ollama_rs::generation::completion::request::GenerationRequest;
use ollama_rs::generation::images::Image;
use ollama_rs::Ollama;
use regex::Regex;
use std::collections::HashMap;
use std::fs::File;
use std::io::Read;
use std::path::Path;
use std::time::Duration;
use tempfile::TempDir;
use tera::{Context, Tera};
use termimad::{self, MadSkin};

#[derive(serde::Serialize)]
struct IssueTemplateContext {
    source_link: String,
    description: String,
    reason: String,
    has_key_media: bool,
}

const ISSUE_TEMPLATE: &str = r#"
**Source**: {{ source_link }}

## Description
>description generated by LLM based on the conversation

{{ description }}

{% if has_key_media %}
> Note: Key images from the conversation are displayed in the Key Media section below.
{% endif %}

<details>
<summary>Think</summary>

{{ reason }}
</details>
"#;

pub async fn run(args: Args) -> Result<()> {
    let args = merge_settings_with_args(&args)?;

    let mm_client = MattermostClient::new(args.mm_url, args.mm_token);
    let gitlab_client = GitLabClient::new(args.gitlab_url, args.gitlab_token, args.project_id);

    let (_team_name, post_id) = MattermostClient::parse_permalink(&args.permalink)?;
    let thread = mm_client.get_thread(&post_id).await?;

    let mut conversation = get_conversation_from_thread(&thread, &post_id, &mm_client).await?;

    // Initialize Ollama client
    let ollama = Ollama::default();

    // Process and analyze images in conversation
    let mut key_media_ids =
        process_images_in_conversation(&mut conversation, &mm_client, &ollama).await?;

    let spinner = ProgressBar::new_spinner();
    spinner.set_style(
        ProgressStyle::default_spinner()
            .template("{spinner} {msg}")
            .unwrap(),
    );
    spinner.set_message("Generating title and description from LLM...");
    spinner.enable_steady_tick(Duration::from_millis(100));

    let (ai_title, ai_description, ai_reason, highlighted_files) =
        analyze_conversation(&conversation, args.ollama_model, &args.prompt, &ollama).await?;

    spinner.finish_and_clear();

    // Merge highlighted_files with key_media_ids
    for file_id in highlighted_files {
        if !key_media_ids.contains(&file_id) {
            // Mark the file as a key media in the conversation
            for conv in conversation.iter_mut() {
                if let Some(image_files) = &mut conv.image_files {
                    if let Some(image_info) = image_files.get_mut(&file_id) {
                        image_info.is_key_media = true;
                    }
                }
            }

            key_media_ids.push(file_id);
        }
    }

    let title = args.title.unwrap_or(ai_title);

    let description = format_issue_description(
        &args.permalink,
        &ai_description,
        &ai_reason,
        !key_media_ids.is_empty(),
    )?;

    let (final_title, final_description) = if !args.no_preview {
        preview_and_confirm(&title, &description)?
    } else {
        (title, description)
    };

    let conversation_markdown = format_conversation_and_attachments(
        &conversation,
        &mm_client,
        &gitlab_client,
        &key_media_ids,
    )
    .await?;

    let issue = Issue {
        title: final_title.clone(),
        description: format!("{final_description}\n\n{conversation_markdown}"),
    };

    let issue_url = gitlab_client.create_issue(&issue).await?;
    println!("Successfully created issue: {}", issue_url);

    if !args.no_reply {
        let post = mm_client.get_post(&post_id).await?;
        let reply = format!(
            ":gitlab: This conversation is now tracked in GitLab Issue: [{}]({})",
            final_title, issue_url
        );
        mm_client
            .create_post(&post.channel_id, &reply, Some(&post_id))
            .await?;
        println!("Successfully posted reply in Mattermost thread");
    }

    Ok(())
}

async fn get_conversation_from_thread(
    thread: &Thread,
    target_post_id: &str,
    mm_client: &impl MattermostApi,
) -> Result<Vec<Conversation>> {
    let target_post = thread
        .posts
        .get(target_post_id)
        .ok_or_else(|| anyhow::anyhow!("Target post not found"))?;
    let target_timestamp = target_post.create_at;

    let mut user_cache: HashMap<String, String> = HashMap::new();
    let mut conversations = Vec::new();

    // Iterate through posts in order using the thread's order field
    for post_id in &thread.order {
        if let Some(post) = thread.posts.get(post_id) {
            // Only include posts at or after the target timestamp
            if post.create_at >= target_timestamp {
                let user_id = &post.user_id;
                let username = if let Some(username) = user_cache.get(user_id) {
                    username.clone()
                } else {
                    // Fetch and cache user details
                    let user = mm_client.get_user(user_id).await?;
                    let username = match (user.first_name, user.last_name) {
                        (Some(first), Some(last)) => {
                            if (!first.is_empty()) && (!last.is_empty()) {
                                format!("{} {}", first, last)
                            } else {
                                user.username
                            }
                        }
                        (Some(first), None) => first,
                        (None, Some(last)) => last,
                        (None, None) => user.username,
                    };
                    user_cache.insert(user_id.clone(), username.clone());
                    username
                };

                // Create image file map if the post has files
                let mut image_files = None;
                if let Some(file_ids) = &post.file_ids {
                    if let Some(meta_files) = &post.metadata.files {
                        let mut image_map = HashMap::new();

                        for meta_file in meta_files {
                            // Check if the file is an image by mime_type
                            if meta_file.mime_type.starts_with("image/") {
                                image_map.insert(
                                    meta_file.id.clone(),
                                    crate::models::ImageFileInfo {
                                        file_id: meta_file.id.clone(),
                                        filename: meta_file.name.clone(),
                                        mime_type: meta_file.mime_type.clone(),
                                        analysis: None,
                                        is_key_media: false,
                                    },
                                );
                            }
                        }

                        if !image_map.is_empty() {
                            image_files = Some(image_map);
                        }
                    }
                }

                conversations.push(Conversation {
                    username,
                    timestamp: Local
                        .timestamp_millis_opt(post.create_at)
                        .single()
                        .ok_or_else(|| anyhow::anyhow!("Invalid timestamp"))?,
                    message: post.message.clone(),
                    file_ids: post.file_ids.clone(),
                    image_files,
                });
            }
        }
    }

    Ok(conversations)
}

async fn analyze_conversation(
    conversation: &[Conversation],
    ollama_model: String,
    prompt_template: &str,
    ollama: &Ollama,
) -> Result<(String, String, String, Vec<String>)> {
    // Create a formatted conversation that includes image analysis in context
    let formatted_conv: String = conversation
        .iter()
        .map(|c| {
            let mut message = format!("{}: {}", c.username, c.message);
            // Add rich image analysis context to help the LLM understand the images
            if let Some(image_files) = &c.image_files {
                if !image_files.is_empty() {
                    message.push_str("\n\n[This user uploaded images with the following content:]");
                    for (_, image_info) in image_files {
                        if let Some(analysis) = &image_info.analysis {
                            // Extract key elements from the analysis
                            let lower_analysis = analysis.to_lowercase();
                            let image_type = if lower_analysis.contains("screenshot") {
                                "screenshot"
                            } else if lower_analysis.contains("diagram") {
                                "diagram"
                            } else if lower_analysis.contains("chart") || lower_analysis.contains("graph") {
                                "chart/graph"
                            } else if lower_analysis.contains("error") || lower_analysis.contains("warning") {
                                "error message"
                            } else if lower_analysis.contains("ui") || lower_analysis.contains("interface") {
                                "UI element"
                            } else {
                                "image"
                            };
                            message.push_str(&format!(
                                "\n- Image '{}' ({}) shows: {}",
                                image_info.filename,
                                image_type,
                                analysis.trim()
                            ));
                        }
                    }
                    // Add an explicit hint for the LLM to use this information
                    message.push_str("\n[Please use the above image descriptions to help understand the issue context]");
                }
            }
            message
        })
        .collect::<Vec<_>>()
        .join("\n\n");

    let mut context = Context::new();
    context.insert("conversation", &formatted_conv);

    let mut tera = Tera::default();
    let prompt = tera.render_str(prompt_template, &context)?;
    debug!("feeding prompt to LLM:\n{prompt}");

    let req = GenerationRequest::new(ollama_model, prompt);
    let response = ollama.generate(req).await?;

    let content = response.response;
    debug!("received response:\n{content}");

    let think_regex = Regex::new(r"(?ms)<think>(.*?)</think>\n?")?;

    let reason = think_regex
        .captures(&content)
        .and_then(|cap| cap.get(1))
        .map_or_else(String::new, |m| m.as_str().trim().to_string());

    let content = think_regex.replace_all(&content, "").trim().to_string();

    let mut lines = content.lines();

    let title = lines
        .next()
        .map(|line| line.trim_start_matches("title:").trim())
        .unwrap_or("Untitled Issue")
        .to_string();

    let description = lines
        .collect::<Vec<_>>()
        .join("\n")
        .trim_start_matches("description:")
        .trim()
        .to_string();

    let description = if description.is_empty() {
        "No description provided.".to_string()
    } else {
        description
    };

    // Extract file_ids mentioned in the description and reason
    let mut highlighted_files = Vec::new();
    for conv in conversation {
        if let Some(image_files) = &conv.image_files {
            for (file_id, image_info) in image_files {
                if let Some(analysis) = &image_info.analysis {
                    // Check if the filename or analysis is mentioned in the description or reason
                    let analysis_lower = analysis.to_lowercase();
                    let description_lower = description.to_lowercase();
                    let reason_lower = reason.to_lowercase();

                    if description_lower.contains(&analysis_lower)
                        || reason_lower.contains(&analysis_lower)
                        || description_lower.contains(&image_info.filename.to_lowercase())
                    {
                        highlighted_files.push(file_id.clone());
                    }
                }
            }
        }
    }

    Ok((title, description, reason, highlighted_files))
}

async fn format_conversation_and_attachments(
    conversations: &[Conversation],
    mm_client: &impl MattermostApi,
    gitlab_client: &impl GitLabApi,
    key_media_ids: &[String],
) -> Result<String> {
    let temp_dir = TempDir::new()?;
    let mut markdown_lines = Vec::new();
    let mut key_media_section = Vec::new();

    let progress = ProgressBar::new(
        conversations
            .iter()
            .filter(|c| c.file_ids.is_some())
            .map(|p| p.file_ids.as_ref().unwrap().len())
            .sum::<usize>() as u64,
    );

    for post in conversations.iter() {
        markdown_lines.push(format_conversation(post));

        if let Some(file_ids) = &post.file_ids {
            for file_id in file_ids {
                match mm_client.download_file(file_id).await {
                    Ok((filename, content, content_type)) => {
                        let file_path = temp_dir.path().join(&filename);
                        tokio::fs::write(&file_path, &content).await?;

                        match gitlab_client.upload_file(&file_path).await {
                            Ok(upload) => {
                                let file_markdown = format!("{}{{width=60%}}\n", upload.markdown);
                                markdown_lines.push(file_markdown.clone());

                                // If this is a key media file, add it to the key media section
                                if key_media_ids.contains(file_id) {
                                    key_media_section.push(format!(
                                        "### Image: {} (from {})\n{}\n\n**Context**: {}\n",
                                        filename,
                                        post.username,
                                        file_markdown,
                                        post.message.replace("\n", " ")
                                    ));
                                }
                            }
                            Err(e) => {
                                eprintln!(
                                    "Failed to upload file {}: {}, use mattermost link instead",
                                    file_id, e
                                );

                                let file_link = format!(
                                    "- [{}]({})\n",
                                    filename,
                                    mm_client.get_file_url(file_id)
                                );
                                markdown_lines.push(file_link.clone());

                                // If this is a key media file, add it to the key media section
                                if key_media_ids.contains(file_id) {
                                    key_media_section.push(format!(
                                        "### Image: {} (from {})\n{}\n\n**Context**: {}\n",
                                        filename,
                                        post.username,
                                        file_link,
                                        post.message.replace("\n", " ")
                                    ));
                                }
                            }
                        }

                        progress.inc(1);
                    }
                    Err(e) => eprintln!("Failed to download file {}: {}", file_id, e),
                }
            }
        }
    }

    progress.finish_and_clear();

    // Create the final markdown
    let mut final_markdown = String::new();

    // Add key media section if there are any key media files
    if !key_media_section.is_empty() {
        final_markdown.push_str("## Key Media\n\n");
        final_markdown.push_str(&key_media_section.join("\n"));
        final_markdown.push_str("\n\n");
    }

    // Add conversation thread
    final_markdown.push_str(&format!(
        "<details>\n\
            <summary>Conversation Thread</summary>\n\n\
            {}\n\
            </details>",
        markdown_lines.join("\n\n")
    ));

    Ok(final_markdown)
}

fn format_conversation(conversation: &Conversation) -> String {
    format!(
        "**{}** ({}): {}",
        conversation.username,
        conversation.timestamp.format("%Y-%m-%d %H:%M:%S"),
        conversation.message
    )
}

fn format_issue_description(
    source_link: &str,
    ai_description: &str,
    ai_reason: &str,
    has_key_media: bool,
) -> Result<String> {
    let template_context = IssueTemplateContext {
        source_link: source_link.to_string(),
        description: ai_description.to_string(),
        reason: ai_reason.to_string(),
        has_key_media,
    };

    let mut tera = Tera::default();
    let context = Context::from_serialize(&template_context)
        .map_err(|e| anyhow::anyhow!("Failed to create template context: {}", e))?;
    tera.render_str(ISSUE_TEMPLATE, &context)
        .map_err(|e| anyhow::anyhow!("Failed to render template: {}", e))
}

fn preview_and_confirm(title: &str, description: &str) -> Result<(String, String)> {
    let skin = MadSkin::default();

    println!(
        "{}",
        skin.term_text(&format!(
            "\n---\nIssue Preview\n---\n# {title}\n\n{description}"
        ))
    );

    loop {
        let choice = dialoguer::Select::new()
            .with_prompt("What would you like to do?")
            .items(&["Proceed", "Edit", "Cancel"])
            .default(0)
            .interact()?;

        match choice {
            0 => return Ok((title.to_string(), description.to_string())),
            1 => {
                if let Ok(Some(edited_content)) = Editor::new().extension(".md").edit(&format!(
                    "Title: {}\n{}\n\n{}",
                    title,
                    "=".repeat(80),
                    description
                )) {
                    let lines: Vec<&str> = edited_content.lines().collect();
                    let new_title = lines[0].replace("Title: ", "").trim().to_string();
                    let new_description = lines[2..].join("\n");
                    return Ok((new_title, new_description));
                }
            }
            2 => return Err(anyhow::anyhow!("Operation cancelled by user")),
            _ => unreachable!(),
        }
    }
}

async fn analyze_image_with_llava(file_path: &Path, ollama: &Ollama) -> Result<String> {
    debug!("Analyzing image: {:?}", file_path);

    // Read the image file
    let mut file = File::open(file_path)?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)?;
    // Convert to base64

    let base64_image = general_purpose::STANDARD.encode(buffer);

    // Create a request with image base64 embedded in the prompt
    let prompt = "You are a senior developer and technical writer checking images uploaded in a support channel. Analyze this image and describe what user tries to report with image.";

    let req = GenerationRequest::new("llava:13b".into(), prompt)
        .images(vec![Image::from_base64(base64_image)]);

    // Send the request to Ollama with better error handling
    match ollama.generate(req).await {
        Ok(response) => {
            debug!("Image analysis result: {}", response.response);
            Ok(response.response)
        }
        Err(e) => Err(anyhow::anyhow!(e)),
    }
}

async fn process_images_in_conversation(
    conversations: &mut Vec<Conversation>,
    mm_client: &impl MattermostApi,
    ollama: &Ollama,
) -> Result<Vec<String>> {
    debug!("Processing images in conversation");
    let mut key_media_ids = Vec::new();
    let spinner = ProgressBar::new_spinner();
    spinner.set_style(
        ProgressStyle::default_spinner()
            .template("{spinner} {msg}")
            .unwrap(),
    );
    spinner.set_message("Analyzing images...");
    spinner.enable_steady_tick(Duration::from_millis(100));

    let temp_dir = TempDir::new()?;
    let mut image_errors = 0;

    // First pass: download and analyze images
    for (conv_index, conv) in conversations.iter_mut().enumerate() {
        debug!("Processing conversation {}: {}", conv_index, conv.username);
        if let Some(image_files) = &mut conv.image_files {
            // Check if message contains keywords indicating the image might be important
            let message_lower = conv.message.to_lowercase();
            let message_suggests_important = message_lower.contains("error")
                || message_lower.contains("issue")
                || message_lower.contains("bug")
                || message_lower.contains("problem")
                || message_lower.contains("fail")
                || message_lower.contains("crash")
                || message_lower.contains("here's")
                || message_lower.contains("look at this")
                || message_lower.contains("screenshot");

            for (file_id, image_info) in image_files.iter_mut() {
                spinner.set_message(format!("Analyzing image: {}...", image_info.filename));
                debug!("Processing image file_id: {}", file_id);

                // Download the file
                match mm_client.download_file(file_id).await {
                    Ok((filename, content, content_type)) => {
                        let file_path = temp_dir.path().join(&filename);
                        tokio::fs::write(&file_path, &content).await?;
                        debug!(
                            "Downloaded image to {:?}, size: {} bytes, type: {}",
                            file_path,
                            content.len(),
                            content_type
                        );

                        // Analyze the image - wrapped in a tokio spawn to handle timeouts
                        let analysis_result = tokio::time::timeout(
                            Duration::from_secs(30), // 30 second timeout
                            analyze_image_with_llava(&file_path, ollama),
                        )
                        .await;

                        match analysis_result {
                            Ok(Ok(analysis)) => {
                                debug!("Successfully analyzed image {}: {}", file_id, analysis);
                                image_info.analysis = Some(analysis);

                                // Mark as key media based on analysis content or message context
                                let lower_analysis =
                                    image_info.analysis.as_ref().unwrap().to_lowercase();

                                // Check analysis content
                                let analysis_suggests_important = lower_analysis
                                    .contains("screenshot")
                                    || lower_analysis.contains("error")
                                    || lower_analysis.contains("diagram")
                                    || lower_analysis.contains("chart")
                                    || lower_analysis.contains("graph")
                                    || lower_analysis.contains("ui")
                                    || lower_analysis.contains("interface")
                                    || lower_analysis.contains("app")
                                    || lower_analysis.contains("application");

                                if analysis_suggests_important || message_suggests_important {
                                    debug!("Marking image {} as key media", file_id);
                                    image_info.is_key_media = true;
                                    key_media_ids.push(file_id.clone());
                                }
                            }
                            Ok(Err(e)) => {
                                image_errors += 1;
                                eprintln!("Failed to analyze image {}: {}", file_id, e);
                                debug!("Error analyzing image {}: {}", file_id, e);
                                // Still provide a generic analysis to avoid breaking the flow
                                image_info.analysis = Some(format!(
                                    "This is a {} image file, but automated analysis couldn't be performed.", 
                                    content_type.split('/').last().unwrap_or("unknown")
                                ));
                            }
                            Err(_) => {
                                image_errors += 1;
                                eprintln!("Timeout analyzing image {}", file_id);
                                debug!("Timeout analyzing image {}", file_id);
                                // Still provide a generic analysis for timeout case
                                image_info.analysis = Some(
                                    "This is an image file, but analysis timed out.".to_string(),
                                );
                            }
                        }
                    }
                    Err(e) => {
                        image_errors += 1;
                        eprintln!("Failed to download image {}: {}", file_id, e);
                        debug!("Error downloading image {}: {}", file_id, e);
                    }
                }
            }
        }
    }

    spinner.finish_and_clear();

    if image_errors > 0 {
        debug!("Completed image processing with {} errors", image_errors);
        eprintln!(
            "Note: {} images couldn't be fully analyzed but processing will continue.",
            image_errors
        );
    } else {
        debug!("Successfully processed all images");
    }

    Ok(key_media_ids)
}
